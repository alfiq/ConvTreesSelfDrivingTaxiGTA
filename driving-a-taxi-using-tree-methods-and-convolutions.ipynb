{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/elcientfico/driving-a-taxi-using-tree-methods-and-convolutions?scriptVersionId=148523120\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Input,Conv2D,GlobalMaxPooling2D# Input data files are available in the read-only \"../input/\" directory\nfrom tensorflow.keras.models import Model# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nfrom PIL import Image\nimport os\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"im_size = Image.open(\"/kaggle/input/gta-san-andreas-driving-dataset-with-label/GTA_SanAndreasDriving/screenshots/1000_1010.png\").size\nim_size = (im_size[1],im_size[0],3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class conv_model:\n    def __init__(self):\n        pass\ndef conv_model(ishape = (512,512,3), filters = 256, kernel_s = 3, strides = 3):\n    x1  = Input(shape = ishape)\n    if len(ishape)<3:\n        x2 = tf.expand_dims(x1,-1)\n        x2 = Conv2D(filters,kernel_s,strides = strides)(x2)\n    else:\n        x2 = Conv2D(filters,kernel_s,strides = strides)(x1)\n    x3 = Conv2D(filters,kernel_s,strides = strides)(x2)\n    x4 = GlobalMaxPooling2D()(x3)\n    model = Model(x1,x4)\n    return model\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = conv_model(im_size,64,3,2)\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ss_path = \"/kaggle/input/gta-san-andreas-driving-dataset-with-label/GTA_SanAndreasDriving/screenshots\"\nfile_list = os.listdir(ss_path)\nkeys = [\"W\",\"S\",\"A\",\"D\"]\nkeys_list = np.array([list(file_name.split(\"_\")[1].split(\".\")[0]) for file_name in file_list]).astype(int)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"LAod images","metadata":{}},{"cell_type":"code","source":"image_gen = tf.keras.utils.image_dataset_from_directory(\n    ss_path,\n    labels=None,\n    color_mode='rgb',\n    batch_size=16,\n    image_size=im_size[:2],\n    shuffle=False,\n    seed=None,\n    validation_split=None,\n    subset=None,\n    interpolation='bilinear',\n    follow_links=False,\n    crop_to_aspect_ratio=False\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\nenc_img_list = model.predict(image_gen,steps = len(image_gen))\n# for image_path in tqdm(file_list):\n#     im = np.array(Image.open(os.path.join(ss_path,image_path)))\n#     im = np.expand_dims(im/255,0)\n#     conv_im = model.predict(im,verbose = False)\n#     enc_img_list.append(conv_im)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"enc_img_list = np.array(enc_img_list).squeeze()\nkeys_list = np.array(keys_list)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import xgboost as xgb","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#[\"W\",\"S\",\"A\",\"D\"]\n\ndef mullab_to_mulclass(y):\n    if all(y == [1,0,0,0]):\n        return [1,0,0,0,0,0,0,0,0]\n    elif all(y == [0,1,0,0]):\n        return [0,1,0,0,0,0,0,0,0]\n    elif all(y == [0,0,1,0]):\n        return [0,0,1,0,0,0,0,0,0]\n    elif all(y == [0,0,0,1]):\n        return [0,0,0,1,0,0,0,0,0]\n    elif all(y == [1,1,0,0]):\n        return [0,0,0,0,1,0,0,0,0]\n    elif all(y == [1,0,1,0]):\n        return [0,0,0,0,0,1,0,0,0]\n    elif all(y == [0,1,1,0]):\n        return [0,0,0,0,0,0,1,0,0]\n    elif all(y == [0,0,1,1]):\n        return [0,0,0,0,0,0,0,1,0]\n    else:\n        return [0,0,0,0,0,0,0,0,1]\nylabels = []\nfor label in keys_list.astype(int):\n    ylabels.append(mullab_to_mulclass(label))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":60,"outputs":[{"execution_count":60,"output_type":"execute_result","data":{"text/plain":"array([ 68.62947083,  73.19006348, 110.25669861, ..., 102.90882111,\n        79.11593628,  61.74182129])"},"metadata":{}}]},{"cell_type":"code","source":"prev_steps = 1\nenc_img_list_plus_prev = np.array(enc_img_list)\nfor step in range(1,prev_steps+1):\n    enc_img_list_0 = np.concatenate(\n        (enc_img_list[:-step],np.zeros(shape = enc_img_list[:step,:].shape))\n        ,0\n    )\n    enc_img_list_plus_prev = np.concatenate((enc_img_list_plus_prev,enc_img_list_0),axis = -1)","metadata":{"execution":{"iopub.status.busy":"2023-10-30T02:55:38.314483Z","iopub.execute_input":"2023-10-30T02:55:38.314951Z","iopub.status.idle":"2023-10-30T02:55:38.325002Z","shell.execute_reply.started":"2023-10-30T02:55:38.314915Z","shell.execute_reply":"2023-10-30T02:55:38.323834Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(enc_img_list_plus_prev,ylabels,test_size=.2)","metadata":{"execution":{"iopub.status.busy":"2023-10-30T02:55:40.024476Z","iopub.execute_input":"2023-10-30T02:55:40.024914Z","iopub.status.idle":"2023-10-30T02:55:40.036311Z","shell.execute_reply.started":"2023-10-30T02:55:40.024878Z","shell.execute_reply":"2023-10-30T02:55:40.034986Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import HistGradientBoostingClassifier\nfrom sklearn.multioutput import MultiOutputClassifier\nfrom sklearn.metrics import f1_score\n# rf = MultiOutputClassifier(HistGradientBoostingClassifier(early_stopping = True, verbose  = True,max_iter = 10000, learning_rate = 0.01,\n#                                                          n_iter_no_change = 100, scoring = \"f1\",min_samples_leaf = 1, \n#                                                           max_leaf_nodes = 14))\n\n    \nearly_stop = xgb.callback.EarlyStopping(\nrounds=5, metric_name='logloss', save_best=True,\n)\n\nprint(\"traing...\")\n\nrf = xgb.XGBClassifier(n_estimators = 1000,callbacks=[early_stop], learning_rate = .1, eval_metric = \"logloss\")\n\nrf.fit(x_train,y_train,eval_set=[(x_test, y_test)], verbose = True)\n\nprint(\"Test Acc\",rf.score(x_test,y_test),\n\"Train Acc\",rf.score(x_train,y_train))\n\nprint(\"Test F1\",f1_score(y_test,rf.predict(x_test),average = \"micro\"),\n\"Train F1\",f1_score(y_train,rf.predict(x_train),average = \"micro\"))\n","metadata":{"execution":{"iopub.status.busy":"2023-10-30T03:14:55.436357Z","iopub.execute_input":"2023-10-30T03:14:55.436744Z","iopub.status.idle":"2023-10-30T03:15:13.411984Z","shell.execute_reply.started":"2023-10-30T03:14:55.436688Z","shell.execute_reply":"2023-10-30T03:15:13.410764Z"},"trusted":true},"execution_count":72,"outputs":[{"name":"stdout","text":"traing...\n[0]\tvalidation_0-logloss:0.62683\n[1]\tvalidation_0-logloss:0.57269\n[2]\tvalidation_0-logloss:0.52768\n[3]\tvalidation_0-logloss:0.49009\n[4]\tvalidation_0-logloss:0.45806\n[5]\tvalidation_0-logloss:0.43097\n[6]\tvalidation_0-logloss:0.40763\n[7]\tvalidation_0-logloss:0.38739\n[8]\tvalidation_0-logloss:0.36988\n[9]\tvalidation_0-logloss:0.35472\n[10]\tvalidation_0-logloss:0.34139\n[11]\tvalidation_0-logloss:0.32989\n[12]\tvalidation_0-logloss:0.31979\n[13]\tvalidation_0-logloss:0.31107\n[14]\tvalidation_0-logloss:0.30337\n[15]\tvalidation_0-logloss:0.29631\n[16]\tvalidation_0-logloss:0.29039\n[17]\tvalidation_0-logloss:0.28521\n[18]\tvalidation_0-logloss:0.28057\n[19]\tvalidation_0-logloss:0.27651\n[20]\tvalidation_0-logloss:0.27304\n[21]\tvalidation_0-logloss:0.26976\n[22]\tvalidation_0-logloss:0.26716\n[23]\tvalidation_0-logloss:0.26484\n[24]\tvalidation_0-logloss:0.26266\n[25]\tvalidation_0-logloss:0.26088\n[26]\tvalidation_0-logloss:0.25938\n[27]\tvalidation_0-logloss:0.25804\n[28]\tvalidation_0-logloss:0.25699\n[29]\tvalidation_0-logloss:0.25601\n[30]\tvalidation_0-logloss:0.25513\n[31]\tvalidation_0-logloss:0.25406\n[32]\tvalidation_0-logloss:0.25342\n[33]\tvalidation_0-logloss:0.25290\n[34]\tvalidation_0-logloss:0.25230\n[35]\tvalidation_0-logloss:0.25172\n[36]\tvalidation_0-logloss:0.25149\n[37]\tvalidation_0-logloss:0.25145\n[38]\tvalidation_0-logloss:0.25133\n[39]\tvalidation_0-logloss:0.25111\n[40]\tvalidation_0-logloss:0.25096\n[41]\tvalidation_0-logloss:0.25091\n[42]\tvalidation_0-logloss:0.25100\n[43]\tvalidation_0-logloss:0.25080\n[44]\tvalidation_0-logloss:0.25070\n[45]\tvalidation_0-logloss:0.25079\n[46]\tvalidation_0-logloss:0.25086\n[47]\tvalidation_0-logloss:0.25096\n[48]\tvalidation_0-logloss:0.25110\n[49]\tvalidation_0-logloss:0.25128\nTest Acc 0.2276707530647986 Train Acc 0.5022991022553098\nTest F1 0.31137724550898205 Train F1 0.6588269037716907\n","output_type":"stream"}]},{"cell_type":"code","source":"from PIL import Image, ImageDraw, ImageFont\nimport cv2\nimport os\n\n# Directory containing the input images\nimage_dir = \"input_images/\"\n\n# List of image file names in the directory\nimage_files = sorted(os.listdir(image_dir))\n\n# Output video file name\noutput_video = \"output_video.mp4\"\n\n# Text to overlay and its color\ntext = \"Hello, World!\"\ntext_color = (255, 0, 0)  # Red color (R, G, B)\n\n# Create a drawing context\nfont = ImageFont.load_default()\n\n# Video settings\nframe_rate = 30\nframe_size = im_size # Adjust the size as needed\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Video codec\n\n# Initialize the video writer\nout = cv2.VideoWriter(output_video, fourcc, frame_rate, frame_size)\n\n# Iterate through the images and add text, then write to the video\nfor image_file in image_files:\n    # Load the image\n    image = Image.open(os.path.join(image_dir, image_file))\n\n    # Create a drawing context\n    draw = ImageDraw.Draw(image)\n\n    # Specify the position for the text (adjust as needed)\n    position = (im_size[0]/2, 8*im_size[1]/9)\n\n    # Draw the text on the image\n    draw.text(position, text, fill=text_color, font=font,align = \"center\")\n\n    # Convert the Pillow image to a NumPy array (OpenCV format)\n    image_np = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n\n    # Write the frame to the video\n    out.write(image_np)\n\n# Release the video writer\nout.release()\n\nprint(f\"Video saved as {output_video}\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}